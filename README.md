# ğŸŒ Web Data Crawler â€“ Projekt PRiR

Aplikacja rozproszona do automatycznego pobierania, selekcji i zapisu danych z witryn internetowych, stworzona w ramach przedmiotu **Przetwarzanie rÃ³wnolegÅ‚e i rozproszone (PRiR)**.

---

## ğŸ“Œ Opis projektu

Projekt opiera siÄ™ na architekturze mikroserwisowej i pozwala uÅ¼ytkownikowi:

- podaÄ‡ adresy URL do przeszukania,
- wybraÄ‡ **profil danych** do ekstrakcji,
- uruchomiÄ‡ **asynchroniczny i wieloprocesowy crawler**,
- obejrzeÄ‡ wyniki w graficznym interfejsie webowym (Flask),
- dane sÄ… zapisywane w bazie danych **MongoDB**.

---

## ğŸ” Profile danych (do wyboru)

- ğŸ“§ Adresy e-mail
- â˜ï¸ Numery telefonÃ³w
- ğŸ  Adresy pocztowe
- ğŸŒ Linki do mediÃ³w spoÅ‚ecznoÅ›ciowych

---

## ğŸ§± Architektura

Projekt skÅ‚ada siÄ™ z trzech gÅ‚Ã³wnych moduÅ‚Ã³w, kaÅ¼dy uruchamiany w osobnym kontenerze Docker:

---

## âš™ï¸ Technologie

- **Python 3.11**
- **Flask** â€“ frontend (UI)
- **FastAPI** â€“ backend API
- **MongoDB** â€“ baza danych
- **BeautifulSoup** â€“ parsowanie HTML
- **aiohttp** â€“ pobieranie asynchroniczne
- **multiprocessing** â€“ rÃ³wnolegÅ‚e przetwarzanie
- **Docker + docker-compose** â€“ konteneryzacja

---

## ğŸš€ Jak uruchomiÄ‡

1. **Sklonuj repozytorium:**
   ```bash
   git clone https://github.com/twoj_login/twoj_projekt.git
   cd twoj_projekt
   docker-compose up --build

